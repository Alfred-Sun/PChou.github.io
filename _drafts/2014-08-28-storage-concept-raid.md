---
layout: postlayout
title: 存储技术之磁盘冗余阵列(RAID)
categories: [hardware]
tags: [Hardware,storage,RAID]
---

存储技术如今已经越来越重要，而且在云计算时代，涌现出了很多专注于云存储的厂商。存储技术本身也十分复杂，从硬件到协议到软件到接口几乎覆盖计算机科学的方方面面。笔者借助《大话存储II》这本书，开始了这块知识空白的补充。本文的图片均来源于网络。


## 软件实现RAID

如果主机没有硬件的RAID控制器，可以使用操作系统自带的软RAID程序实现RAID。原理其实也很简单：程序将SCSI提交上来的磁盘信息通过配置好的RAID策略，分割合并再交给操作系统的上层模块；同时，操作系统对磁盘的读写操作都要经过这层软件进行重新的安排，然后转变成真正的磁盘操作指令。这层程序虽然起到了RAID的作用，但是程序本身的执行还是需要CPU参与运算，因此，软件RAID对系统性能有一定的影响，仅仅能够实现对磁盘的RAID功能。

## 硬件RAID

### RAID卡

![](http://i3.sinaimg.cn/IT/cr/2009/0721/2028045085.jpg)

软件RAID虽然能够实现RAID，但是有如下缺点：

- CPU和内存占用
- 无法对操作系统所在分区进行RAID，因为程序本身运行在操作系统上

为了解决以上缺点，专用的硬件RAID卡被开发出来。这种RAID卡可以独立的实现RAID功能，不需要CPU和内存，也无需主机操作系统的参与，可见RAID卡本身就是一个完整的计算系统，有运算器和存储器，因此，RAID卡一般成本比较高。操作系统只需要有相应的RAID卡驱动程序即可。对于操作系统而言，经过RAID卡提交上来的磁盘，已经是经过RAID“虚拟过”的了，不是真实的物理磁盘数量。

> 也有RAID功能集成在南桥芯片中的（南桥芯片直接与IO沟通）。

由于RAID卡连接了主机和磁盘（主机通过PCI总线，磁盘通过SCSI总线），因此RAID卡同时拥有PCI控制器和SCSI控制器，将PCI总线上传过来的磁盘操作指令经过翻译再通过RAID卡自己的SCSI控制器发出去，控制链接在RAID卡所在SCSI总线上的磁盘运转。RAID在实现RAID的过程中必然需要使用某种算法已经将映射关系储存下来，但是不同厂商的RAID卡做法不同，如果RAID卡坏了，磁盘就成了废材。因此，SNIA协会定义了一种DDF RAID信息标准格式，以使得不同厂商的RAID信息保持兼容。

`0通道RAID卡`比较特殊，其本身没有SCSI控制器和总线接口，它需要利用同样插在主机PCI上的其他SCSI卡来识别磁盘（这些磁盘是链接在SCSI卡上的）。0通道RAID卡需要主板电路的支持。


### RAID卡上的内存

RAID卡在执行代码的时候需要RAM，所以RAID卡上有内存。不过RAID卡的内存还有一个用处，就是缓存。缓存的一个作用是适配告诉的运算器和低速的IO控制器，另一个作用就是对IO进行缓存。就像磁盘本身内部的缓存一样，缓存用于对IO进行队列化和各种优化。对于上层的写IO，有两种策略：

1. `WriteBack`模式：即当RAID控制器收到IO，并将IO缓存进队列后，就通知上层IO完成。这样做可以使上层系统“觉得”IO速度加快了，但是一个明显的问题是RAM是掉电数据就丢失了。所以一些高端的RAID卡还自带电池，在掉电时可以将缓存的数据刷回ROM，下次加电的时候再把缓存从ROM中加载回来，并将未完成的IO写入磁盘。
2. `WriteThrough`模式：即RAID控制器只有真正将数据写入磁盘后才会通知上层IO完成。这样保证了较高的可靠性。

除了写缓存之外，RAID卡还具有读缓存能力，依靠复杂的缓存算法，“猜测”主机需要访问的数据，提前读入缓存，称为`预读(Prefetch)`。

### RAID的改进

- RAID组再划分：随着单个磁盘的容量越来越大，一个RAID组的总容量也越来越大。这时，超大容量对于上层系统来说有些不够灵活。于是RAID控制还支持将已经组好的RAID组进一步划分为虚拟磁盘。比如5块100G磁盘做RAID5，那么实际的容量为400G(100G校验)。如果不划分的话，操作系统将看到一块400G的物理磁盘；如果RAID组此时将400G划分为4块100G的虚拟磁盘，那么操作系统将看到4块100G的物理磁盘。虽然，此时的总容量没变，但是操作系统看到的物理磁盘并不是真正的物理盘，是RAID划分出来的虚拟磁盘。如果实际的物理磁盘损坏，对于操作系统而言没有任何影响，4块盘还是好好的。
- 一个通道多种类型：RAID还支持一个通道下划分出多种不同类型的RAID。比如8块100G的磁盘，可以将5块组成RAID5，另外3块组成RAID0。这样操作系统看到的将是两块物理磁盘，一块400G，一块300G。而且每个RAID类型还可以再像上面那样划分。


## 卷管理(Volume Manager)

### 卷管理的原理

RAID在硬件层面提高了物理磁盘的性能、可靠性和利用率，它提供给上层操作系统虚拟的磁盘，在操作系统看来是物理磁盘。但是，随之带来的问题是，如果某块虚拟的磁盘哪一天不够用了怎么办？无法动态的添加容量。为了解决这个问题，在操作系统和RAID(或直接的磁盘控制器)之间产生了一种叫卷管理器(Volume Manager)的软件。

卷管理器将RAID提交上来的磁盘进行再划分和再重组，使得操作系统可以自由的对卷进行管理。为了理解卷管理，首先来看几个概念：

- `PV(Physical Volume)`：即是RAID提交上来的虚拟磁盘(对于卷管理器而言它是物理磁盘)，只是换个名词，提交上来几个虚拟磁盘就有几个PV
- `PE(Physical Extends)`：将PV进行等大小划分出来的物理区块，每个PE都代表着PV上从几号扇区到几号扇区，PE是分割和合并的最小单位，可以在卷管理中设置
- `VG(Volume Group)`：卷管理器将PE进行组合，组成逻辑上的大的容器池，称为VG
- `LV(Logical Volume)`：从VG中将若干数量的PE组合成逻辑卷。在Linux中，一个逻辑卷就可以被挂在到相应的目录。

下面的图可以说明上述的概念之间的关系：

![](http://pchou.qiniudn.com/LVM.jpg)

![](http://www.reader8.cn/uploadfile/jiaocheng/201401101/2917/2014012901170942771.png)

卷管理通过划分PE，将物理的磁盘分割，并进行再重组。这样就可以在某个逻辑卷空间不足时将其他逻辑卷的PE搬一些过来使用。所以对于上层操作系统而言，逻辑卷是灵活多了。但是，这些关系是如此的繁杂，卷管理需要维护这些对应关系，所以需要在磁盘上保存卷配置信息，比如PE大小、初始偏移、PV的数量和信息、排列顺序等。存储这个配置信息的区域叫做`VGDA`(Volume Group Descriptor Area)。当卷管理器初始化时需要从VGDA上加载信息，并生成映射公式，当上层系统发起IO请求时，卷管理器需要换算成实际磁盘及物理扇区位置(当然这些磁盘和物理扇区本身可能都是虚拟的)，并通过驱动程序告知下层的控制器如何存取磁盘。

卷管理器甚至还具有软RAID功能，可以将逻辑卷看成物理磁盘，组成RAID。

### 分区

分区实际上也可以看成一种简单的卷管理，是操作系统自带的卷管理程序，但是只能管理单个磁盘，不能将多个磁盘组合成虚拟卷再划分，不具备灵活的功能。我们通常见到的C:D:E:...盘就是通过分区得到的逻辑卷。操作系统可以对针对分区(逻辑卷)进行格式化。

BIOS在进行引导时，总是会执行LBA1扇区上的指令，以加载操作系统，这个扇区称为`MBR`(Master Boot Recorder)，其中还保存着分区表。通常第一条指令都是跳转到活动分区读取操作系统的代码并执行。在修改了分区设置的后，分区表会被更新。

卷管理程序同样需要遵从BIOS和MBR，只不过它除了各个磁盘上写入VGDA外，也要更新MBR中的分区表，划分出一个小分区，将启动操作系统的代码放在这个分区中，并表明`bootable`类型。在Linux中，这个分区就是`/boot`分区，其中包含有操作系统的启动代码，大约只需要100MB。

> BIOS执行的第一条指令位置总是LBA1，这是固定的。现在提出的新的EFI规范，可以配置第一条指令的所在扇区

在Linux中，每一个硬件设备都映射到一个系统的文件，对于硬盘、光驱等 IDE 或 SCSI 设备也不例外。Linux 把各种`IDE`设备分配了一个由`hd`前缀组成的文件；而对于各种`SCSI`设备，则分配了一个由`sd`前缀组成的文件。例如，第一个IDE设备，Linux就定义为`hda`；第二个IDE设备就定义为`hdb`；下面以此类推。而SCSI设备就应该是`sda`、`sdb`等。每一个硬盘设备最多能有4个`主分区`（其中包含`扩展分区`）构成，任何一个扩展分区都要占用一个主分区号码，也就是在一个硬盘中，主分区和扩展分区一共最多是4个。主分区的作用就是计算机用来进行启动操作系统的，因此每一个操作系统的引导程序，都应该存放在主分区上。扩展分区可以进一步划分为`逻辑分区`。以第一个IDE硬盘为例说明，主分区（或者扩展分区）占用了`hda1`、`hda2`、`hda3`、`hda4`，而逻辑分区占用了`hda5`到`hda16`等12个号码。因此，Linux下每一个硬盘总共最多有16个分区。下面是一个分区的例子：

![](http://zanyzhao.blog.chinaunix.net/attachment/201301/21/20769015_1358743115W8XX.png)


## 文件系统

扇区是存储的最小单位。然而，如果应用程序直接以扇区为单位进行存取，不但大大增加了复杂度，而且还增加了安全隐患。所以，需要由操作系统提供同一个管理接口，应用程序通过调用接口来完成数据的存取。也就是说，操作系统实际上就是在裸(Raw)设备的基础上，对磁盘进行逻辑上的结构化调整，并向上提供操作接口。这样的东东就是文件系统。文件系统对磁盘不同的组织方式就形成了不同的文件系统。例如`FAT32`、`NTFS`、`EXT`...

### EXT文件系统


### 文件系统的IO类型

文件系统的IO类型分为`同步IO`、`异步IO`、`阻塞`/`非阻塞`IO和`Direct IO`。这些分类不是同一层次的，需要分开讨论：

对于应用程序而言，需要调用操作系统文件系统的接口，这种接口可以分为同步IO和异步IO：

- 同步IO是指应用程序的线程发起IO请求后，会被操作系统挂起，直到IO完成后，重新唤醒线程并把结果告知线程。此时，线程会处于等待状态，无法继续执行。
- 异步IO是指操作系统不会挂起发起请求的线程，而是会继续执行该线程，当IO完成后跑到线程的回调函数中，以处理完成的IO结果。异步IO下，线程得以继续执行而不会等待。

阻塞/非阻塞IO是个广义的概念，是指普遍意义上的上层程序向下层程序发起IO请求后是否等待下层程序：

- 阻塞IO情况下上层程序会等待下层程序的返回才继续执行后面的代码
- 非阻塞IO情况下上层程序不会等待下层程序，而是继续执行自己的代码，直到下层程序发起完成通知

同步IO是阻塞IO的一种，异步IO是非阻塞IO的一种。

文件系统具有自己的缓存系统和缓存算法，以实现写速度的提升和“预读”。Direct IO就是告诉文件系统不使用缓存，而是直接将数据写入磁盘。数据库应用是使用Direct IO的典型应用，因为数据库自己有实现一套数据缓存和Flush算法。比如Oracle甚至有独立的进程DBWR来完成数据的Flush。



## 磁盘阵列

### 磁盘柜JBOD

虽然RAID可以用来整合磁盘，但是要把大量的磁盘塞进一个机箱显然是不合适的。于是将磁盘单独从主机中拿出来，放进一个箱子，并配合完整的电源和散热系统，对外提供SCSI接口，内部将SCSI线缆固化在箱子内的印刷电路版上。这样就组成了`JBOD`(Just a Bound Of Disks)。

将JBOD两两相连，还能在容量上进一步扩展。注意到，JBOD只是将磁盘进行一个物理上的组装，SCSI控制器或者RAID控制器还是必须放在主机中

![](http://img.zdnet.com.cn/1/361/li6w1YZE7daoM.jpg?1289189766&random=5606.749718465682)


### 带RAID卡的外置磁盘阵列

如果在JBOD的基础上，将RAID控制器加入磁盘柜，就形成了磁盘阵列。主机与阵列之间仍然通过SCSI接口连接。这样，主机看到的磁盘已经是经过磁盘中阵列虚拟化好了的。

这种磁盘阵列还能有多个对外的SCSI通道，内部的虚拟磁盘称为逻辑单元(`LUN`)，每个LUN都有编号，LUN可以配置成分配给哪个通道使用。

> LUN是SCSI协议中的名词，不过这个概念已经被普遍用于硬件生成的虚拟磁盘，而由软件生成的虚拟磁盘称为卷。

磁盘阵列通常通过COM口或者以太网口进行管理和配置。为了提高可用性，有些盘阵配有两个RAID控制器，以达到冗余的效果。两个RAID控制器需要互相配合工作。

甚至可以将控制器单独提取出来，成为“机头”。机头再通过SCSI接口连接JBOD盘柜，称为“扩展柜”。这样一节接一节就像火车一样。磁盘中阵列的规模可以不断扩大，提供更大的存储容量。


### Fibre Channel协议

